---
layout: post
author: "Yan"
catalog: true
subtitle: "Architecture"
header-img: "img/header/none2.jpg"
title: "배경지식 쌓기 - Dead Letter Queue"
date: 2024-08-31 23:15:08 +0000
categories:
  - CS
tags:
  - Message
comments: true
---

# DLQ(Dead Letter Queue)란?

애플리케이션이 메시지를 처리하는 과정에서 예상치 못한 문제가 발생할 수 있다. 메시지가 특정 조건을 만족하지 않거나, 여러 번의 재시도에도 불구하고 성공적으로 처리되지 않는 경우, 이러한 메시지는 어떻게 처리해야 할까? 이때 사용되는 것이 바로 Dead Letter Queue(DLQ)이다.

## DLQ의 개념

Dead Letter Queue는 메시징 시스템에서 처리되지 않은 메시지를 별도로 보관하는 큐다. 메시지 브로커가 설정한 규칙에 따라 처리할 수 없거나 실패한 메시지를 이 큐에 보낸다. 이를 통해 실패한 메시지를 다른 메시지와 분리하여 관리할 수 있다.

DLQ는 주로 다음과 같은 상황에서 사용된다:

1. **메시지 형식 오류**: 메시지가 예상된 형식이 아니거나, 필요한 필드가 누락된 경우.
2. **처리 제한 초과**: 메시지가 여러 번 처리 시도 후에도 실패한 경우.
3. **메시지 유효 기간 초과**: 메시지가 지정된 시간 내에 처리되지 않은 경우.

### DLQ의 장점

DLQ를 사용하면 실패한 메시지를 안전하게 보관하고, 이를 분석하여 문제를 진단할 수 있다. 또한, 주 애플리케이션의 흐름에 지장을 주지 않고 문제 메시지를 격리할 수 있어 시스템 안정성을 높인다.

1. **문제 진단**: DLQ에 저장된 메시지를 분석함으로써, 왜 특정 메시지가 실패했는지 파악할 수 있다. 이를 통해 버그를 수정하거나 시스템의 처리 로직을 개선할 수 있다.
2. **재처리 가능**: DLQ에 쌓인 메시지는 나중에 별도로 처리하거나 재시도할 수 있다. 이로 인해 메시지를 완전히 잃어버리는 것을 방지할 수 있다.
3. **시스템 안정성**: 처리 실패한 메시지가 주 애플리케이션의 메시지 큐를 가득 채우는 것을 방지하여, 전체 시스템의 성능 저하를 막을 수 있다.

### DLQ 설정 시 고려사항

DLQ를 설정할 때는 몇 가지 중요한 사항을 고려해야 한다.

1. **재시도 횟수**: 메시지가 몇 번의 재시도 후 DLQ로 보내질지 결정해야 한다. 너무 많은 재시도는 시스템 자원을 낭비할 수 있고, 너무 적은 재시도는 메시지가 불필요하게 DLQ로 이동할 수 있다.
2. **모니터링 및 알림**: DLQ에 메시지가 쌓이는 상황은 곧 시스템의 문제를 의미할 수 있다. 따라서 DLQ를 모니터링하고, 일정 기준을 초과할 경우 알림을 설정하여 신속하게 대응할 수 있도록 해야 한다.
3. **메시지 처리 전략**: DLQ에 쌓인 메시지를 어떻게 처리할지에 대한 전략을 사전에 수립해야 한다. 재처리, 삭제, 로그 분석 등 다양한 방법을 고려할 수 있다.

### API Rate Limiting란?
API Rate Limiting은 API에 대한 요청 수를 일정 시간 동안 제한하는 메커니즘이다. 주로 서비스의 안정성을 유지하고, 특정 API에 대한 과도한 요청으로 인해 발생할 수 있는 문제를 방지하기 위해 사용된다. 예를 들어, 특정 API가 초당 100개의 요청만 허용한다고 설정하면, 그 한도를 초과하는 요청은 차단되거나 지연 처리된다.

#### 왜 Rate Limit 알고리즘이 필요한가?
- 과도한 트래픽으로부터 서비스를 보호.
- Resource 사용에 대한 공정성과 합리성 유도.
- 트래픽 비용이 서비스 예산을 넘는 것을 방지.
- Rate에 대해 과금을 부과하는 Business Model로 활용.

### Rate Limiting 알고리즘

#### 1. Token Bucket Algorithm

![](https://www.mimul.com/static/34b0a436c691568360a9e46dc7baca1d/ff42b/rate_tokenbucket.png)

Token Bucket Algorithm은 가장 널리 사용되는 Rate Limiting 알고리즘 중 하나다. 이 알고리즘은 다음과 같은 방식으로 작동한다

- 일정한 속도로 토큰을 버킷에 추가한다. 버킷은 정해진 크기를 가지고 있으며, 최대 크기를 초과할 수 없다.
- 클라이언트가 요청을 보낼 때마다 버킷에서 토큰 하나를 소모한다. 만약 버킷에 토큰이 남아있지 않다면 요청이 거부되거나 지연된다.
- 토큰이 버킷에 충분히 있다면 요청이 즉시 처리된다.

이 알고리즘은 burst 트래픽(짧은 시간 내에 집중된 트래픽)을 허용하면서도 전체적인 요청 속도를 제한하는 데 유용하다.

#### 2. Leaky Bucket Algorithm

![](https://www.mimul.com/static/53e202f8b985d2acb8fd7081248688ce/b5245/rate_leakybucket.png)

Leaky Bucket Algorithm은 토큰 버킷 알고리즘과 비슷하지만, 트래픽 흐름을 더욱 일정하게 유지하도록 설계되었다.

- 버킷에 물(데이터 패킷)이 들어오면, 일정한 속도로 물이 새어 나온다.
- 만약 버킷에 물이 넘치면 초과된 물(추가 요청)은 버려진다.

이 알고리즘은 트래픽이 갑자기 증가하는 것을 방지하고, 일정한 속도로 트래픽을 처리하는 데 효과적이다.

#### 3. Fixed Window Counter

![](https://www.mimul.com/static/fc309200b26de4d6322f48fd3719518a/0a47e/rate_fixed_window_counter.png)

Fixed Window Counter는 간단하면서도 효과적인 방법이다.

- 일정한 시간 창(예: 1분, 1시간 등)을 정의하고, 그 시간 동안의 요청 수를 카운트한다.
- 요청 수가 설정한 한도를 초과하면, 해당 시간 창이 끝날 때까지 추가 요청이 거부된다.

이 방법은 구현이 간단하지만, 시간 창 경계에서 트래픽이 집중될 때 "thundering herd" 문제(한 시간 창의 끝에서 시작으로 넘어가는 시점에 많은 요청이 몰리는 현상)가 발생할 수 있다.

#### 4. Sliding Window Log

![](https://www.mimul.com/static/75653188f6e1eb96a9e9bf861f538f6e/90712/rate_sliding-window-log.png)

Sliding Window Log는 Fixed Window Counter의 문제를 해결하기 위해 고안된 알고리즘이다.

- 요청이 발생할 때마다 타임스탬프를 기록하고, 이 타임스탬프를 기반으로 일정한 시간 창 내의 요청 수를 계산한다.
- 시간 창 내의 요청 수가 한도를 초과하면 요청이 거부된다.

이 알고리즘은 시간 창 경계에서 발생하는 트래픽 집중 문제를 줄여준다. 하지만 타임스탬프를 저장해야 하므로 메모리 사용량이 증가할 수 있다.

#### 5. Sliding Window Counter

![](https://www.mimul.com/static/1823b61524cd87ef9438cdca3d395a92/6b1e2/rate_sliding-window.png)

Sliding Window Counter는 Sliding Window Log와 유사하지만, 메모리 효율성을 높이기 위한 방법이다.

- 시간을 작은 구간(예: 1초)으로 나누고, 각 구간의 요청 수를 카운트한다.
- 전체 시간 창 동안의 요청 수를 계산하기 위해 현재 구간과 이전 구간의 카운트를 사용하여 요청 수를 계산한다.

이 방식은 로그를 저장할 필요가 없으므로 메모리 사용량이 줄어들지만, 여전히 시간 창 경계에서 약간의 부정확성이 발생할 수 있다.

#### 6. Exponential Backoff
Exponential Backoff는 주로 요청 실패 시 재시도 전략으로 사용되지만, Rate Limiting과 함께 적용할 수 있다.

- 클라이언트가 요청을 보냈을 때, 실패한 경우 재시도 간격을 기하급수적으로 증가시킨다.
- 이 방법은 서버 과부하를 방지하고, 클라이언트의 요청이 연속적으로 거부되는 것을 방지하는 데 유용하다.

이 방법은 주로 API Rate Limiting 상황에서 요청을 관리하고, 시스템에 부하를 줄이기 위한 보조 전략으로 사용된다.

> Token Bucket이나 Leaky Bucket 같은 알고리즘은 버스트 트래픽을 관리하는 데 효과적이고, Fixed Window Counter나 Sliding Window Counter는 구현이 단순하면서도 실용적이다. Exponential Backoff는 재시도 로직에 유용하게 적용할 수 있는 추가적인 전략이다.

### DLQ와 Rate Limiting

#### Rate Limiting에 따른 요청 실패 처리:

- 만약 애플리케이션이 외부 API에 요청을 보내고, 해당 API가 Rate Limiting에 의해 요청을 거부하는 경우가 있다. 이때, 요청 실패가 발생할 수 있으며, 이를 적절히 처리하지 않으면 시스템의 문제로 이어질 수 있다.
- 만약 요청이 여러 번 재시도된 후에도 API가 요청을 수락하지 않으면, 이 실패한 요청을 DLQ로 보내는 방식을 고려할 수 있다. 이를 통해 Rate Limiting에 의해 실패한 요청을 나중에 분석하고 재처리할 수 있다.

#### Rate Limiting에 따른 재시도 전략:

- API Rate Limiting이 적용된 시스템에서, 애플리케이션이 요청을 보낼 때 Rate Limiting에 걸리면 일정 시간 후 재시도를 하게 된다. 이러한 재시도는 여러 번 실패할 수 있고, 최종적으로 이 요청이 더 이상 처리될 수 없다고 판단될 경우 DLQ에 보내질 수 있다.
- 예를 들어, 특정 API에 대한 요청이 지속적으로 Rate Limiting에 걸린다면, 이 메시지를 DLQ로 이동시키고, 시스템 운영자는 이를 분석하여 Rate Limiting의 원인을 파악하거나, 요청 간격을 조정하는 등의 조치를 취할 수 있다.

#### 결론

Dead Letter Queue는 메시징 시스템에서 발생할 수 있는 오류를 효과적으로 관리할 수 있는 강력한 도구다. 이를 통해 시스템의 안정성을 높이고, 문제 발생 시 빠르게 대응할 수 있는 유연성을 제공한다. DLQ를 올바르게 설정하고 관리하면, 메시징 애플리케이션의 전반적인 품질과 신뢰성을 크게 향상시킬 수 있다. DLQ를 통해 장애 상황에서도 데이터 손실을 최소화하고, 지속적인 서비스 운영이 가능하게 된다.




###### reference

> [DLQ(Dead Letter Queue)란 무엇인가요?](https://aws.amazon.com/ko/what-is/dead-letter-queue/)
> [서비스 가용성 확보에 필요한 Rate Limiting Algorithm에 대해](https://www.mimul.com/blog/about-rate-limit-algorithm/)